Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!spool.mu.edu!sgiblab!adagio.panasonic.com!nntp-server.caltech.edu!keith
From: keith@cco.caltech.edu (Keith Allan Schneider)
Newsgroups: alt.atheism
Subject: Re: Objective morality (was Re: <Political Atheists?)
Date: 16 Apr 1993 07:06:37 GMT
Organization: California Institute of Technology, Pasadena
Lines: 44
Message-ID: <1qllttINNarg@gap.caltech.edu>
References: <1q0fngINNahu@gap.caltech.edu> <1q28ok$dt7@fido.asd.sgi.com> <1q56olINN8g9@gap.caltech.edu> <1q5gnr$s0g@fido.asd.sgi.com> <1q8m6kINNj4i@gap.caltech.edu> <1qcqfv$r05@fido.asd.sgi.com> <1ql7utINN5sg@gap.caltech.edu> <1qlci4$bqp@fido.asd.sgi.com> <1qlf7gINN8sn@gap.caltech.edu> <1qlgvj$dm1@fido.asd.sgi.com>
NNTP-Posting-Host: lloyd.caltech.edu

livesey@solntze.wpd.sgi.com (Jon Livesey) writes:

>Humans have "gone somewhat beyond" what, exactly?    In one thread
>you're telling us that natural morality is what animals do to
>survive, and in this thread you are claiming that an omniscient
>being can "definitely" say what is right and what is wrong.   So
>what does this omniscient being use for a criterion?   The long-
>term survival of the human species, or what?

Well, that's the question, isn't it?  The goals are probably not all that
obvious.  We can set up a few goals, like happiness and liberty and
the golden rule, etc.  But these goals aren't inherent.  They have to
be defined before an objective system is possible.

>How does omniscient map into "definitely" being able to assign
>"right" and "wrong" to actions?

It is not too difficult, one you have goals in mind, and absolute
knoweldge of everyone's intent, etc.

>>Now you are letting an omniscient being give information to me.  This
>>was not part of the original premise.
>Well, your "original premises" have a habit of changing over time,
>so perhaps you'd like to review it for us, and tell us what the
>difference is between an omniscient being be able to assign "right"
>and "wrong" to actions, and telling us the result, is. 

Omniscience is fine, as long as information is not given away.  Isn't
this the resolution of the free will problem?  An interactive omniscient
being changes the situation.

>>Which type of morality are you talking about?  In a natural sense, it
>>is not at all immoral to harm another species (as long as it doesn't
>>adversely affect your own, I guess).
>I'm talking about the morality introduced by you, which was going to
>be implemented by this omniscient being that can "definitely" assign
>"right" and "wrong" to actions.
>You tell us what type of morality that is.

Well, I was speaking about an objective system in general.  I didn't
mention a specific goal, which would be necessary to determine the
morality of an action.

keith
