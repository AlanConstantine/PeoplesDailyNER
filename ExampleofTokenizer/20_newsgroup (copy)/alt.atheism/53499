Newsgroups: alt.atheism
Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!zaphod.mps.ohio-state.edu!howland.reston.ans.net!usenet.ins.cwru.edu!agate!doc.ic.ac.uk!uknet!mcsun!news.funet.fi!ousrvr.oulu.fi!kempmp
From: kempmp@phoenix.oulu.fi (Petri Pihko)
Subject: Re: Consciousness part II - Kev Strikes Back!
Message-ID: <1993Apr22.005914.1416@ousrvr.oulu.fi>
Sender: news@ousrvr.oulu.fi
Organization: University of Oulu, Finland
X-Newsreader: TIN [version 1.1 PL9]
References: <1993Apr21.163848.8099@cs.nott.ac.uk>
Date: Thu, 22 Apr 1993 00:59:14 GMT
Lines: 207

Kevin Anthoney (kax@cs.nott.ac.uk) wrote:

(about my reply)

> Diplomatic :-)

It a society that is constantly on the verge of flaming, Usenet, diplomacy
is the best way to ensure the voice of reason gets through, isn't it?

> I realize I'm fighting Occam's razor in this argument, so I'll try to
> explain why I feel a mind is necessary. 

Kevin, unfortunately you are now delving into field I know too little
about, algorithms. Your reasoning, as I see it, is very much along the
lines of Roger Penrose, who claimed that mathematical 'insight' cannot
be algorithmic in his book _The emperor's new mind: Concerning
computers, minds, and the laws of physics_. However, Penrose's
claim that he _has_ mathematical insight, or your similar claim
that wavefunctions collapse only when we consciously take a look,
could be just illusions.

We are obviouslu taking very different viewpoints - I try to ponder
on the problem of consciousness from an evolutionary perspective,
realising that it might not be anything special, but certainly
useful. Thinking back of what I wrote, do you think worms have minds
or not? They are able to experience pain, at least they behave 
just like that. Yet it is conceivable that we might some day
in the future perform a "total synthesis of C. elegans" from
the elements. Would such a worm have a mind?

> Firstly, I'm not impressed with the ability of algorithms. They're
> great at solving problems once the method has been worked out, but not
> at working out the method itself.

This is true to some extent. However, I do not think that our brains
work like computers, at all. In fact, there is substantial evidence
(Skarda, 1985; Skarda & Freeman 1987) that brains work more or less
chaotically, generating enough randomness for mental states to evolve.
Our brains work much like genetic algorithm generators, I suppose.

> the trick still has to be there in some form to be discovered. Does
> this mean that all the ideas we will ever have are already
> pre-programmed into our brains? This is somewhat unlikely, given that
> our brains ultimately are encoded in 46 chromosomes worth of genetic
> material, much of which isn't used.

Indeed, this is extremely unlikely, given the vast impact of nurture
on our mind and brain. I suggest, however, that before trying to
understand our consciousness as a collection of algorithms. 

Kevin, take a look at the references I mentioned, and think again.
I still think the best experts on the nature of a conscious mind
are neurologists, neuropsychologists and biologists (but do not 
flame me for my opinions), since they study beings that are
conscious. 

The reason I am repeating my advice is that this discussion cannot
lead to anywhere if our backgrounds are too different.

And please, do not bring QM into this discussion at all - not
all physicists are happy with the claim that our consciousness
plays some special role in physics. I would say it doesn't.

> The other problem with algorithms is their instability. Not many
> algorithms survive if you take out a large portion of their code, yet
> people survive strokes without going completely haywire (there are
> side-effects, but patients still seem remarkably stable.) Also,
> neurons in perfectly healthy people are dying at an alarming rate -
> can an algorithm survive if I randomly corrupt various bits of it's
> code?

Again, _brains are not computers_. Don't forget this. This does not
mean they need something else to work - they just work differently.
Their primary 'purpose' is perception and guidance of action, 
self-awareness and high intelligence are later appearances.

> The next problem is the sticky question of "What is colour?" (replace
> 'colour' with the sensation of your choice.) Presumably, the
> materialist viewpoint is that it's the product of some kind of
> chemical reaction. The usual products of such a reaction are energy +
> different chemicals. Is colour a mixture of these?

You are still expecting that we could find the idea of 'green' in
our brains somewhere, perhaps in the form of some chemical. This is
not how I see it. The sensation 'green' is a certain time-dependent
pattern in the area V4 of our visual cortex, and it is distributed
with the help of areas V1 and V2 to the rest of the brain. 

Indeed, a firing pattern. I have sometimes thought of our consciousness
as a global free induction pattern of these local firing patterns,
but this is just idle speculation.

Scientific American's September 1992 issue was a special issue on
mind and brain. Have you already read it from cover to cover? ;-)
There are two articles on visual perception, so you might be 
interested.

But again, please note that subjective experiences cannot be 
observed from a third-person perspective. If we see nothing but 
neuronal activity, we cannot go on to conclude that this is not the
mind.

Kalat (1988) writes about numerous examples where electric stimulation
of different areas of brain have led to various changes in the 
patients' state of mind. For instance, a patient whose septal area
was stimulated (without his knowledge) by remote control during
a psychiatric interview was quickly cured of his depression, and
started discussing a plan to seduce his girlfriend.

Stimulations in the temporal lobe have sometimes led to embarrassing
situations, when the patients have started flirting with the
therapist.

In conclusion, there is evidence that

1) brains are essentially necessary for subjective experiences, 
   brain damage is usually equivalent to some sort of mind damage

2) conscious processes involve substantial brain activity in
   various areas of brain - when we think of colours, our
   visual cortex is activated etc.

3) consciousness is an afterthought - we become conscious of our
   actions with a half a second delay, and our brains are ahead
   of our 'conscious will' by at least 350 ms. 

Thus, I think it is fruitful to turn the question "Why do 'I' see
colours" around and ask "What is this 'I' that seems to be 
observing?", since it seems that our conscious mind is not
the king of our brains.

> If this is so, a
> computer won't see colour, because the chemistry is different. Does an
> algorithm that sees colour have a selective advantage over an
> equivalent that doesn't? It shouldn't, because the outputs of each
> algorithm ought to be the same in equivalent circumstances. So why do
> we see colour?

This depends on what is meant by 'seeing colours'. Does a neural
network that is capable of recognising handwritten numbers from
0 to 9 see the numbers, if it is capable of sorting them?

If you are asking, "why does an animal who is conscious of itself
as an observer have an evolutionary advantage over an animal who
doesn't", I have a good answer - read my previous posting,
where I wrote why a sense of identity helps social animals to swap
roles and act more morally, so that they don't unconsciously
kill each other with newly discovered weapons. (A bit extreme,
but this is the basic idea.)

When early _Homo_ became more and more efficient in using tools, 
a sense of identity and the concept of 'self' had to evolve in
line with this development. Indeed, respect for others and 
conscious altruistic behaviour might be evolutionary advantages
for social animals, such as early humans. 

> If I remember correctly, quantum mechanics consists of a wavefunction,
> with two processes acting on it. The first process has been called
> 'Unitary Evolution' (or 'U'), is governed by Schroedinger's equation
> and is well known. The second process, called various things such as
> 'collapse of the wavefunction' or 'state vector reduction' (or 'R'),
> and is more mysterious. It is usually said to occur when a
> 'measurement' takes place, although nobody seems to know precisely
> when that occurs. When it does occur, the effect of R is to abruptly
> change the wavefunction.

If minds are required for this, does this mean that until human
minds came to the scene, wavefunctions never collapsed, but remained
in the superpositions for aeons? My, how powerful we are.

This has been discussed before, and I think this topic is irrelevant,
since we do not agree that minds are necessary, and neither do
physicists. 

> Anyway, I'm speculating that minds would be in part X. There seems to
> be some link between consciousness and R, in that we never see linear
> superpositions of anything, although there are alternative
> explainations for this. I've no idea how a brain is supposed to access
> part X, but since this is only speculation, that won't matter too
> much :-) My main point is that there might be a place for minds in
> physics.

I agree, but not in the sense you apparently mean above - physics
needs sharp minds to solve many real problems. ;-)

> I'll go back to my nice padded cell now, if that's OK with you :-)

It's OK, if you don't forget to take with you the references I
wrote about in my previous posting, plus the following:

Kalat, James W. (1988): Biological Psychology.
3rd ed., Wadsworth Publishing Company, Belmont, CA 1988.

Skarda, C. (1985): Explaining behavior: Bringing the brain back in.
Inquiry 29:187-202.

Skarda, C. & Freeman, W. (1987): How brains make chaos in order to
make sense of the world. 
Behavioral and Brain Sciences 10:161-173.

Petri

--
 ___. .'*''.*        Petri Pihko    kem-pmp@          Mathematics is the Truth.
!___.'* '.'*' ' .    Pihatie 15 C    finou.oulu.fi    Physics is the Rule of
       ' *' .* '*    SF-90650 OULU  kempmp@           the Game.
          *'  *  .*  FINLAND         phoenix.oulu.fi  -> Chemistry is The Game.
